"""
Anomaly Detection Optimizer - Simplified Academic Version

Clase simplificada para optimizaci칩n de hiperpar치metros y evaluaci칩n
de combinaciones de features. Enfoque acad칠mico con m칠todos esenciales.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import ParameterGrid
from itertools import combinations
from typing import Dict, Optional, List


class AnomalyOptimizer:
    """
    Optimizador simplificado para detecci칩n de anomal칤as.
    
    Funcionalidades principales:
    - Optimizaci칩n de hiperpar치metros
    - Evaluaci칩n de combinaciones de features (feature selection)
    """
    
    def __init__(self, core_detector=None):
        """
        Inicializar optimizador.
        
        Parameters:
        - core_detector: Instancia del detector principal
        """
        self.core_detector = core_detector
    
    def _evaluate_single_feature_combination(self, features: List[str], param_grid: Dict) -> Dict:
        """
        游댢 Evaluar una combinaci칩n espec칤fica de features con mean_score.
        
        Parameters:
        - features: Lista de features a usar
        - param_grid: Grid de par치metros a probar
        
        Returns:
        - Dict con mejores par치metros y scores para esta combinaci칩n
        """
        # Preparar datos con solo las features seleccionadas
        X_train = self.core_detector.train_df_clean[features].dropna()
        X_test = self.core_detector.test_df_clean[features].dropna()
        
        # Usar los m칠todos del DataScaler del orchestrator
        X_train_scaled = self.core_detector.scaler.scaler.fit_transform(X_train)
        X_test_scaled = self.core_detector.scaler.scaler.transform(X_test)
        
        all_results = []
        
        # Probar cada configuraci칩n de par치metros
        for params in ParameterGrid(param_grid):
            model = IsolationForest(random_state=42, **params)
            model.fit(X_train_scaled)
            
            # Solo calcular mean_score (es lo m치s importante)
            test_scores = -model.decision_function(X_test_scaled)
            mean_score = test_scores.mean()
            
            all_results.append({
                **params,
                'mean_score': mean_score
            })
        
        # Simplemente usar el mejor mean_score
        results_df = pd.DataFrame(all_results)
        best_idx = results_df['mean_score'].idxmax()
        best_result = results_df.loc[best_idx]
        
        return {
            'best_params': {k: v for k, v in best_result.items() if k in param_grid.keys()},
            'mean_score': best_result['mean_score']
        }
    
    def evaluate_feature_combinations(self, feature_sizes: List[int] = None, 
                                     param_grid: Optional[Dict] = None) -> Dict:
        """
        游댌 Evaluar diferentes combinaciones de features + hiperpar치metros.
        
        Esta funci칩n prueba subsets de features de diferentes tama침os
        para encontrar la mejor combinaci칩n de variables y par치metros.
        
        Parameters:
        - feature_sizes: Lista de tama침os de combinaciones a probar (ej: [2, 3, 4])
        - param_grid: Grid de hiperpar치metros (usa default si None)
        - max_combinations: M치ximo n칰mero de combinaciones por tama침o
        
        Returns:
        - Dict con mejores combinaciones y resultados
        """
        if not self.core_detector:
            raise ValueError("Core detector no asignado")
        
        all_features = self.core_detector.features.copy()
        
        # Tama침os por defecto
        if feature_sizes is None:
            max_size = len(all_features)
            feature_sizes = list(range(2, min(max_size + 1, 6)))  # 2 a 5 features
        
        # Grid por defecto - VALORES CONSERVADORES
        if param_grid is None:
            param_grid = {
                'n_estimators': [100, 200, 300],
                'contamination': [0.01,0.03, 0.05],
                'max_samples': ['auto', 50, 170]
            }
        
        print(f"游댌 Evaluando combinaciones de features: {feature_sizes}")
        print(f"   Features disponibles: {all_features}")
        
        all_results = []
        
        for size in feature_sizes:
            print(f"\n游꿢 Probando combinaciones de {size} features...")
            
            # Generar todas las combinaciones de este tama침o
            feature_combinations = list(combinations(all_features, size))
            
            for i, feature_combo in enumerate(feature_combinations):
                
                # Evaluar esta combinaci칩n con grid search
                combo_results = self._evaluate_single_feature_combination(
                    list(feature_combo), param_grid
                )
                
                # Agregar metadata
                combo_results['feature_combination'] = list(feature_combo)
                combo_results['n_features'] = len(feature_combo)
                
                all_results.append(combo_results)
        
        # Encontrar la mejor combinaci칩n global - SIMPLIFICADO
        results_df = pd.DataFrame(all_results)
        
        # Usar mean_score directamente (m치s simple y confiable)
        best_idx = results_df['mean_score'].idxmax()
        best_result = results_df.loc[best_idx]
        
        print(f"\n游끥 MEJOR COMBINACI칍N ENCONTRADA:")
        print(f"   Features: {best_result['feature_combination']}")
        print(f"   Par치metros: {best_result['best_params']}")
        print(f"   Mean Score: {best_result['mean_score']:.4f}")
        
        return {
            'best_combination': {
                'features': best_result['feature_combination'],
                'params': best_result['best_params'],
                'score': best_result['mean_score'],
                'n_features': best_result['n_features']
            },
            'all_results': results_df,
            'summary_by_size': results_df.groupby('n_features')['mean_score'].agg(['mean', 'max', 'count'])
        }


