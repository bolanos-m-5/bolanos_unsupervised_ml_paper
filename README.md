# ğŸ¯ Polaris Analytics - ML System for Retail Business Intelligence

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3%2B-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)

## ğŸ“‹ DescripciÃ³n

Sistema integrado de **Machine Learning no supervisado** para anÃ¡lisis de negocio en retail que combina scoring dinÃ¡mico multidimensional, detecciÃ³n de anomalÃ­as mediante Isolation Forest y clustering jerÃ¡rquico optimizado. DiseÃ±ado bajo la metodologÃ­a **CRISP-DM** con arquitectura modular end-to-end para garantizar reproducibilidad y escalabilidad.

### ğŸ¯ Objetivo del Proyecto

Transformar grandes volÃºmenes de datos financieros operacionales (ventas, gastos, indicadores) en **inteligencia comercial accionable** mediante:

- **Scoring dinÃ¡mico** que evalÃºa performance de clientes, canales y equipos
- **DetecciÃ³n automÃ¡tica de anomalÃ­as** sin umbrales arbitrarios
- **SegmentaciÃ³n de clientes** en grupos homogÃ©neos para estrategias diferenciadas

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ† Scoring DinÃ¡mico Multidimensional
- Sistema de ponderaciÃ³n automÃ¡tica de 4 mÃ©tricas clave (Rate NOS, NOS SU, Variaciones)
- Benchmarks calculados dinÃ¡micamente por perÃ­odo fiscal
- Penalizaciones automÃ¡ticas para crecimientos negativos
- TransformaciÃ³n a escala [0-10] mediante ranking percentil

### ğŸ” DetecciÃ³n de AnomalÃ­as (Isolation Forest)
- **OptimizaciÃ³n exhaustiva**: 702 experimentos (26 combinaciones de features Ã— 27 configuraciones de hiperparÃ¡metros)
- Grid search automÃ¡tico: `contamination`, `n_estimators`, `max_samples`
- ValidaciÃ³n temporal: entrenamiento 2024, evaluaciÃ³n 2025
- IdentificaciÃ³n de comportamientos atÃ­picos sin umbrales predefinidos

### ğŸ¯ Clustering JerÃ¡rquico Optimizado
- **OptimizaciÃ³n anidada**: Grid search de hiperparÃ¡metros + feature selection paralela
- ComparaciÃ³n automÃ¡tica **SFS vs RFE** (28 combinaciones evaluadas)
- MÃ©todos: Ward, Complete, Average con mÃ©tricas Euclidean, Cosine, Correlation
- Best model: Silhouette Score 0.3413 con 6 clusters interpretables

### ğŸ”§ Pipeline End-to-End Automatizado
- PreparaciÃ³n de datos con validaciÃ³n automÃ¡tica
- AnÃ¡lisis exploratorio integrado
- OrquestaciÃ³n de modelos con clases especializadas
- ExportaciÃ³n automatizada de reportes para consumo en Power BI

---

## ğŸ—ï¸ Arquitectura del Sistema

```
Polaris_DS_Master/
â”‚
â”œâ”€â”€ clases/                                    # MÃ³dulos principales del sistema
â”‚   â”œâ”€â”€ data_preparation/                      # Pipeline de preparaciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ PrepPipeline.py                   # Orquestador principal
â”‚   â”‚   â”œâ”€â”€ data_merge.py                     # IntegraciÃ³n de fuentes
â”‚   â”‚   â”œâ”€â”€ prepare_cust.py                   # Limpieza datos clientes
â”‚   â”‚   â”œâ”€â”€ prepare_nos.py                    # CÃ¡lculo mÃ©tricas NOS
â”‚   â”‚   â”œâ”€â”€ prepare_prod.py                   # Procesamiento productos
â”‚   â”‚   â”œâ”€â”€ quarteralization.py               # AgregaciÃ³n trimestral
â”‚   â”‚   â””â”€â”€ anualizacion.py                   # AgregaciÃ³n anual
â”‚   â”‚
â”‚   â”œâ”€â”€ exploratory_analysis/                  # AnÃ¡lisis exploratorio
â”‚   â”‚   â””â”€â”€ Analisis_exploratorio.py          # EDA automatizado
â”‚   â”‚
â”‚   â”œâ”€â”€ scoring/                               # Sistema de scoring
â”‚   â”‚   â””â”€â”€ NosScore.py                       # Scoring dinÃ¡mico multidimensional
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_models/                             # Modelos de ML
â”‚   â”‚   â”œâ”€â”€ anomaly_detection/                # DetecciÃ³n de anomalÃ­as
â”‚   â”‚   â”‚   â”œâ”€â”€ anomaly_detection_orchestrator.py  # Coordinador principal
â”‚   â”‚   â”‚   â”œâ”€â”€ anomaly_optimizer.py          # HPO con grid search
â”‚   â”‚   â”‚   â””â”€â”€ utilities/                    # Utilidades especializadas
â”‚   â”‚   â”‚       â”œâ”€â”€ anomaly_predictor.py      # PredicciÃ³n de anomalÃ­as
â”‚   â”‚   â”‚       â”œâ”€â”€ anomaly_explainer.py      # InterpretaciÃ³n de resultados
â”‚   â”‚   â”‚       â”œâ”€â”€ anomaly_reporter.py       # GeneraciÃ³n de reportes
â”‚   â”‚   â”‚       â”œâ”€â”€ data_scaler.py            # NormalizaciÃ³n de features
â”‚   â”‚   â”‚       â””â”€â”€ data_validator.py         # ValidaciÃ³n de datos
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ clustering/                        # Clustering jerÃ¡rquico
â”‚   â”‚       â”œâ”€â”€ analyzer.py                   # AnÃ¡lisis e interpretaciÃ³n
â”‚   â”‚       â”œâ”€â”€ estimator.py                  # Algoritmos de clustering
â”‚   â”‚       â”œâ”€â”€ feature_selector.py           # SFS + RFE comparativo
â”‚   â”‚       â””â”€â”€ parameter_grids.py            # Espacios de bÃºsqueda HPO
â”‚   â”‚
â”‚   â””â”€â”€ main_pipelines/                        # Notebooks de ejecuciÃ³n
â”‚       â”œâ”€â”€ Main_Pipeline.ipynb               # Pipeline principal integrado
â”‚       â””â”€â”€ exploratory.ipynb                 # AnÃ¡lisis exploratorio iterativo
â”‚
â”œâ”€â”€ Datasets/                                  # Datos de entrada
â”‚   â”œâ”€â”€ MDM_cust/                             # Master data clientes
â”‚   â”œâ”€â”€ MDM_prod/                             # Master data productos
â”‚   â””â”€â”€ Polaris_reports/                      # Reportes financieros
â”‚
â”œâ”€â”€ Final_Reports/                             # Reportes generados
â”‚   â””â”€â”€ pipeline_results/                     # Resultados del pipeline
â”‚       â”œâ”€â”€ reporte_final_pipeline_*.csv      # Reporte integrado
â”‚       â”œâ”€â”€ resumen_nacional.csv              # AgregaciÃ³n total mercado
â”‚       â”œâ”€â”€ resumen_team.csv                  # AgregaciÃ³n por equipo
â”‚       â”œâ”€â”€ resumen_channel.csv               # AgregaciÃ³n por canal
â”‚       â””â”€â”€ resumen_customer.csv              # AgregaciÃ³n por cliente

```


## ğŸ“Š Uso del Sistema

### 1ï¸âƒ£ Pipeline Completo (EjecuciÃ³n AutomÃ¡tica)

```python
# Abrir notebook principal
jupyter notebook clases/main_pipelines/Main_Pipeline.ipynb

# Ejecutar todas las celdas para pipeline completo:
# âœ… PreparaciÃ³n de datos
# âœ… AnÃ¡lisis exploratorio
# âœ… Scoring dinÃ¡mico
# âœ… DetecciÃ³n de anomalÃ­as
# âœ… Clustering jerÃ¡rquico
# âœ… Reporte consolidado
```

### 2ï¸âƒ£ EjecuciÃ³n Modular (Componentes Individuales)

#### PreparaciÃ³n de Datos
```python
from clases.data_preparation.PrepPipeline import DataPreparationPipeline

pipeline = DataPreparationPipeline(nos_path, cust_path, prod_path)
final_df, missing_stats, product_analysis = pipeline.run()
```

#### Scoring DinÃ¡mico
```python
from clases.ml_models.scoring.NosScore import ScoreDynamic

score_calculator = ScoreDynamic(
    year_data=benchmark_data,
    df=customer_data,
    dimension_cols=['customer', 'channel', 'team']
)
scored_data = score_calculator.calcular_score()
```

#### DetecciÃ³n de AnomalÃ­as
```python
from clases.ml_models.anomaly_detection.anomaly_detection_orchestrator import AnomalyDetectionOrchestrator

orchestrator = AnomalyDetectionOrchestrator(
    train_df=train_data,
    test_df=test_data,
    features=['rate_nsrd', 'rate_sd', 'nos_su', 'variation_rate_nos', 'variation_rate_volume']
)

results = orchestrator.one_call_complete_analysis(
    segment_columns=['channel', 'team'],
    optimize_model=True,
    verbose=False
)
```

#### Clustering JerÃ¡rquico
```python
from clases.ml_models.clustering.analyzer import ClusteringAnalyzer

analyzer = ClusteringAnalyzer(
    data=customer_data,
    min_clusters=5,
    max_clusters=6,
    filter_outliers=True
)

results = analyzer.full_analysis(
    selection_method='sfs_rfe_grid',
    required_features=['SCORE'],
    plot_results=True
)
```

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­as |
|-----------|-------------|
| **Lenguaje** | Python 3.8+ |
| **ML/Data Science** | scikit-learn, NumPy, pandas |
| **VisualizaciÃ³n** | Matplotlib, Seaborn |
| **Notebooks** | Jupyter |
| **MetodologÃ­a** | CRISP-DM |
| **Algoritmos** | Isolation Forest, Hierarchical Clustering (Ward, Complete, Average) |
| **OptimizaciÃ³n** | Grid Search CV, Sequential Feature Selection, Recursive Feature Elimination |

---

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico desarrollado como trabajo de maestrÃ­a. Las contribuciones, sugerencias y feedback son bienvenidos.


---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¤ Autor

**Mario BolaÃ±os GutiÃ©rrez**
- ğŸ“§ Email: mabg020997@gmail.com

---

<div align="center">

### â­ Si este proyecto te fue Ãºtil, considera darle una estrella â­

Made  for Retail Analytics

</div>
